{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cdcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1424d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import Tensor, einsum\n",
    "from einops import parse_shape, rearrange, repeat\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_parameters_all(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b82a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 24])\n",
      "Params: 600\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import AttentionBase, SABlock, RABlock, DMABlock, FeedForwardBlock, TransformerBlock, PatcherBlock, UnpatcherBlock, ConvTention, ConvTeNet\n",
    "        \n",
    "att = AttentionBase(\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4,\n",
    ")\n",
    "q = torch.rand(2, 10, 12)\n",
    "k = torch.rand(2, 20, 12)\n",
    "v = torch.rand(2, 20, 24)\n",
    "print(att(q, k, v).shape)\n",
    "print(f\"Params: {count_parameters(att)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600e1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 24])\n",
      "Params: 1176\n"
     ]
    }
   ],
   "source": [
    "block = SABlock(\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4\n",
    ")\n",
    "\n",
    "out = block(torch.rand(2, 10, 12))\n",
    "print(out.shape)        \n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0371d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 24])\n",
      "Params: 1092\n"
     ]
    }
   ],
   "source": [
    "block = RABlock(\n",
    "    in_tokens = 10,\n",
    "    out_tokens = 5,\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4\n",
    ")\n",
    "\n",
    "out = block(torch.rand(2, 10, 12))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290c9483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 24])\n",
      "Params: 19176\n"
     ]
    }
   ],
   "source": [
    "block = DMABlock(\n",
    "    memory_size = 512,\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4\n",
    ")\n",
    "\n",
    "out = block(torch.rand(2, 10, 12))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e9e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n",
      "Params: 2100736\n"
     ]
    }
   ],
   "source": [
    "block = FeedForwardBlock(\n",
    "    features = 512,\n",
    "    multiplier = 4,\n",
    "    dropout = 0.1\n",
    ")\n",
    "out = block(torch.rand(2, 10, 512))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2443dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 256])\n",
      "Params: 788992\n"
     ]
    }
   ],
   "source": [
    "block = TransformerBlock(\n",
    "    features = 256,\n",
    "    num_heads = 2,\n",
    "    dropout_attention = 0.1,\n",
    "    dropout_mlp = 0.1,\n",
    "    mlp_multiplier = 4\n",
    ")\n",
    "out = block(torch.rand(2, 10, 256))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81886da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [2., 2., 2.],\n",
      "         [3., 3., 3.],\n",
      "         [4., 4., 4.],\n",
      "         [5., 5., 5.],\n",
      "         [6., 6., 6.]]]) torch.Size([1, 6, 3])\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [2., 2., 2.],\n",
      "          [3., 3., 3.]],\n",
      "\n",
      "         [[2., 2., 2.],\n",
      "          [3., 3., 3.],\n",
      "          [4., 4., 4.],\n",
      "          [5., 5., 5.]],\n",
      "\n",
      "         [[4., 4., 4.],\n",
      "          [5., 5., 5.],\n",
      "          [6., 6., 6.],\n",
      "          [0., 0., 0.]]]]) torch.Size([1, 3, 4, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [2., 2., 2.],\n",
      "         [3., 3., 3.],\n",
      "         [4., 4., 4.],\n",
      "         [5., 5., 5.],\n",
      "         [6., 6., 6.]]]) torch.Size([1, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "patcher = PatcherBlock(\n",
    "    kernel_size = 4,\n",
    "    stride = 2,\n",
    "    padding = 1\n",
    ")\n",
    "\n",
    "unpatcher = UnpatcherBlock(\n",
    "    kernel_size = 4,\n",
    "    stride = 2,\n",
    "    padding = 1\n",
    ")\n",
    "x = torch.tensor([[ [1,1,1], [2,2,2], [3,3,3], [4,4,4], [5,5,5], [6,6,6] ]]).float()\n",
    "print(x, x.shape)\n",
    "x = patcher(x)\n",
    "print(x, x.shape)\n",
    "x = unpatcher(x)\n",
    "print(x, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f1e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 256])\n",
      "torch.Size([2, 1024, 256])\n",
      "Params: 3747840\n"
     ]
    }
   ],
   "source": [
    "encode = ConvTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 2,\n",
    "    kernel_size = 4,\n",
    "    stride = 4,\n",
    "    padding = 0,\n",
    "    memory_size = 512,\n",
    "    dropout = 0.1\n",
    ")\n",
    "decode = ConvTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 4,\n",
    "    kernel_size = 2,\n",
    "    stride = 2,\n",
    "    padding = 0,\n",
    "    memory_size = 512,\n",
    "    dropout = 0.1\n",
    ")\n",
    "\n",
    "out = encode(torch.rand(2, 1024, 256))\n",
    "print(out.shape)\n",
    "out = decode(out)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(encode)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e0a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2048, 800])\n",
      "Params: 47382816\n"
     ]
    }
   ],
   "source": [
    "net = ConvTeNet(\n",
    "    vocabulary_size = 800,\n",
    "    embedding_dim = 256,\n",
    "    num_layers = 7,\n",
    "    num_heads = 8,\n",
    "    use_skip = True\n",
    ")\n",
    "\n",
    "x = torch.randint(low=0, high=800, size=(2, 2048))\n",
    "out = net(x)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(net)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ac3ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.]])\n",
      "K,V tensor([[4., 4., 4.],\n",
      "        [3., 3., 3.],\n",
      "        [2., 2., 2.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [0., 0., 0.]]) tensor([[4., 4.],\n",
      "        [3., 3.],\n",
      "        [2., 2.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [2., 2.],\n",
      "        [0., 0.]])\n",
      "Memory: tensor([[3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.],\n",
      "        [8., 8., 8.]])\n",
      "K,V tensor([[8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.],\n",
      "        [8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.]]) tensor([[8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.],\n",
      "        [8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.]])\n",
      "Memory: tensor([[3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.],\n",
      "        [8., 8., 8.]])\n",
      "K,V tensor([[8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.],\n",
      "        [8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.]]) tensor([[8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.],\n",
      "        [8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flavioschneider/Documents/brainle/brainle/models/architectures/attention.py:845: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices).to(q)\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import KVMemory\n",
    "  \n",
    "# Build memory \n",
    "memory = KVMemory(k_features=3, v_features=2, memory_size=6, items_per_query=4)\n",
    "\n",
    "# Inseart and search\n",
    "k, v = torch.tensor([ [1,1,1], [2,2,2], [3,3,3], [4,4,4]]).to(torch.float), torch.tensor([[1,1],[2,2],[3,3], [4,4]]).to(torch.float)\n",
    "memory.insert(k, v)\n",
    "q = torch.tensor([[1,1,1], [0,0,0]]).to(torch.float)\n",
    "k, v = memory(q)\n",
    "print(\"Memory:\",memory.k_memory)\n",
    "print(\"K,V\", k,v)\n",
    "\n",
    "# Insert again (notice that it's FIFO)\n",
    "k, v = torch.tensor([[5,5,5], [6,6,6], [7,7,7], [8,8,8]]).to(torch.float), torch.tensor([[5,5],[6,6],[7,7],[8,8]]).to(torch.float)\n",
    "memory.insert(k, v)\n",
    "q = torch.tensor([[1,1,1],[8,8,8]]).to(torch.float)\n",
    "k, v = memory(q)\n",
    "print(\"Memory:\",memory.k_memory)\n",
    "print(\"K,V\", k,v)\n",
    "\n",
    "# Check state dict stores memory \n",
    "file = './memory.pt'\n",
    "torch.save(memory.state_dict(), file)\n",
    "memory = KVMemory(k_features=3, v_features=2, memory_size=6, items_per_query=4)\n",
    "memory.load_state_dict(torch.load(file))\n",
    "# Query should return same result \n",
    "q = torch.tensor([[1,1,1],[8,8,8]]).to(torch.float)\n",
    "k, v = memory(q)\n",
    "print(\"Memory:\",memory.k_memory)\n",
    "print(\"K,V\", k,v)\n",
    "os.remove(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af74951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034661054611206055\n",
      "torch.Size([4800, 256]) torch.Size([4800, 128])\n"
     ]
    }
   ],
   "source": [
    "memory = KVMemory(k_features=256, v_features=128, memory_size=100_000, items_per_query=16)\n",
    "\n",
    "start = time.time() \n",
    "k, v = memory(torch.rand(300, 256))\n",
    "print(time.time() - start)\n",
    "print(k.shape, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca9fd1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 256])\n",
      "Params: 852224\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import MABlock\n",
    "  \n",
    "block = MABlock(\n",
    "    in_features = 512,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16\n",
    ")\n",
    "\n",
    "out = block(torch.rand(32, 10, 512))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0238ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 256])\n",
      "Params: 854528\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import MemoformerBlock\n",
    "\n",
    "block = MemoformerBlock(\n",
    "    features = 256,\n",
    "    num_heads = 2,\n",
    "    dropout_attention = 0.1,\n",
    "    dropout_mlp = 0.1,\n",
    "    mlp_multiplier = 4,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16\n",
    ")\n",
    "out = block(torch.rand(2, 10, 256))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "723e7b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 256])\n",
      "torch.Size([2, 1024, 256])\n",
      "Params: 4208896\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import ConvMemoTention\n",
    "\n",
    "encode = ConvMemoTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 2,\n",
    "    kernel_size = 4,\n",
    "    stride = 4,\n",
    "    padding = 0,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16,\n",
    "    dropout = 0.1\n",
    ")\n",
    "decode = ConvMemoTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 4,\n",
    "    kernel_size = 2,\n",
    "    stride = 2,\n",
    "    padding = 0,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16,\n",
    "    dropout = 0.1\n",
    ")\n",
    "\n",
    "out = encode(torch.rand(2, 1024, 256))\n",
    "print(out.shape)\n",
    "out = decode(out)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(encode)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d31e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2048, 800])\n",
      "Params: 59346208\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import ConvMeNet\n",
    "\n",
    "net = ConvMeNet(\n",
    "    vocabulary_size = 800,\n",
    "    embedding_dim = 256,\n",
    "    num_layers = 7,\n",
    "    num_heads = 8,\n",
    "    num_attention_layers = 4,\n",
    "    window_size = 4,\n",
    "    use_skip = True,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 8,\n",
    ")\n",
    "\n",
    "x = torch.randint(low=0, high=800, size=(2, 2048))\n",
    "out = net(x)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(net)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22eb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
