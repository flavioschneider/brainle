{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03cdcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc1424d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import Tensor, einsum\n",
    "from einops import parse_shape, rearrange, repeat\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_parameters_all(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b82a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 24])\n",
      "Params: 600\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import AttentionBase, SABlock, RABlock, DMABlock, FeedForwardBlock, TransformerBlock, PatcherBlock, UnpatcherBlock, ConvTention, ConvTeNet\n",
    "        \n",
    "att = AttentionBase(\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4,\n",
    ")\n",
    "q = torch.rand(2, 10, 12)\n",
    "k = torch.rand(2, 20, 12)\n",
    "v = torch.rand(2, 20, 24)\n",
    "print(att(q, k, v).shape)\n",
    "print(f\"Params: {count_parameters(att)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600e1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 24])\n",
      "Params: 1176\n"
     ]
    }
   ],
   "source": [
    "block = SABlock(\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4\n",
    ")\n",
    "\n",
    "out = block(torch.rand(2, 10, 12))\n",
    "print(out.shape)        \n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0371d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 24])\n",
      "Params: 1092\n"
     ]
    }
   ],
   "source": [
    "block = RABlock(\n",
    "    in_tokens = 10,\n",
    "    out_tokens = 5,\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4\n",
    ")\n",
    "\n",
    "out = block(torch.rand(2, 10, 12))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290c9483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 24])\n",
      "Params: 19176\n"
     ]
    }
   ],
   "source": [
    "block = DMABlock(\n",
    "    memory_size = 512,\n",
    "    in_features = 12,\n",
    "    out_features = 24,\n",
    "    num_heads = 4\n",
    ")\n",
    "\n",
    "out = block(torch.rand(2, 10, 12))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e9e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n",
      "Params: 2100736\n"
     ]
    }
   ],
   "source": [
    "block = FeedForwardBlock(\n",
    "    features = 512,\n",
    "    multiplier = 4,\n",
    "    dropout = 0.1\n",
    ")\n",
    "out = block(torch.rand(2, 10, 512))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2443dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 256])\n",
      "Params: 788992\n"
     ]
    }
   ],
   "source": [
    "block = TransformerBlock(\n",
    "    features = 256,\n",
    "    num_heads = 2,\n",
    "    dropout_attention = 0.1,\n",
    "    dropout_mlp = 0.1,\n",
    "    mlp_multiplier = 4\n",
    ")\n",
    "out = block(torch.rand(2, 10, 256))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81886da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [2., 2., 2.],\n",
      "         [3., 3., 3.],\n",
      "         [4., 4., 4.],\n",
      "         [5., 5., 5.],\n",
      "         [6., 6., 6.]]]) torch.Size([1, 6, 3])\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [2., 2., 2.],\n",
      "          [3., 3., 3.]],\n",
      "\n",
      "         [[2., 2., 2.],\n",
      "          [3., 3., 3.],\n",
      "          [4., 4., 4.],\n",
      "          [5., 5., 5.]],\n",
      "\n",
      "         [[4., 4., 4.],\n",
      "          [5., 5., 5.],\n",
      "          [6., 6., 6.],\n",
      "          [0., 0., 0.]]]]) torch.Size([1, 3, 4, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [2., 2., 2.],\n",
      "         [3., 3., 3.],\n",
      "         [4., 4., 4.],\n",
      "         [5., 5., 5.],\n",
      "         [6., 6., 6.]]]) torch.Size([1, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "patcher = PatcherBlock(\n",
    "    kernel_size = 4,\n",
    "    stride = 2,\n",
    "    padding = 1\n",
    ")\n",
    "\n",
    "unpatcher = UnpatcherBlock(\n",
    "    kernel_size = 4,\n",
    "    stride = 2,\n",
    "    padding = 1\n",
    ")\n",
    "x = torch.tensor([[ [1,1,1], [2,2,2], [3,3,3], [4,4,4], [5,5,5], [6,6,6] ]]).float()\n",
    "print(x, x.shape)\n",
    "x = patcher(x)\n",
    "print(x, x.shape)\n",
    "x = unpatcher(x)\n",
    "print(x, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f1e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 256])\n",
      "torch.Size([2, 1024, 256])\n",
      "Params: 3747840\n"
     ]
    }
   ],
   "source": [
    "encode = ConvTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 2,\n",
    "    kernel_size = 4,\n",
    "    stride = 4,\n",
    "    padding = 0,\n",
    "    memory_size = 512,\n",
    "    dropout = 0.1\n",
    ")\n",
    "decode = ConvTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 4,\n",
    "    kernel_size = 2,\n",
    "    stride = 2,\n",
    "    padding = 0,\n",
    "    memory_size = 512,\n",
    "    dropout = 0.1\n",
    ")\n",
    "\n",
    "out = encode(torch.rand(2, 1024, 256))\n",
    "print(out.shape)\n",
    "out = decode(out)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(encode)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e0a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2048, 800])\n",
      "Params: 47382816\n"
     ]
    }
   ],
   "source": [
    "net = ConvTeNet(\n",
    "    vocabulary_size = 800,\n",
    "    embedding_dim = 256,\n",
    "    num_layers = 7,\n",
    "    num_heads = 8,\n",
    "    use_skip = True\n",
    ")\n",
    "\n",
    "x = torch.randint(low=0, high=800, size=(2, 2048))\n",
    "out = net(x)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(net)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ac3ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.]])\n",
      "K,V tensor([[4., 4., 4.],\n",
      "        [3., 3., 3.],\n",
      "        [2., 2., 2.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [0., 0., 0.]]) tensor([[4., 4.],\n",
      "        [3., 3.],\n",
      "        [2., 2.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [2., 2.],\n",
      "        [0., 0.]])\n",
      "Memory: tensor([[3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.],\n",
      "        [8., 8., 8.]])\n",
      "K,V tensor([[8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.],\n",
      "        [8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.]]) tensor([[8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.],\n",
      "        [8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.]])\n",
      "Memory: tensor([[3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.],\n",
      "        [8., 8., 8.]])\n",
      "K,V tensor([[8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.],\n",
      "        [8., 8., 8.],\n",
      "        [7., 7., 7.],\n",
      "        [6., 6., 6.],\n",
      "        [5., 5., 5.]]) tensor([[8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.],\n",
      "        [8., 8.],\n",
      "        [7., 7.],\n",
      "        [6., 6.],\n",
      "        [5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import KVMemory\n",
    "  \n",
    "# Build memory \n",
    "memory = KVMemory(k_features=3, v_features=2, memory_size=6, items_per_query=4)\n",
    "\n",
    "# Inseart and search\n",
    "k, v = torch.tensor([ [1,1,1], [2,2,2], [3,3,3], [4,4,4]]).to(torch.float), torch.tensor([[1,1],[2,2],[3,3], [4,4]]).to(torch.float)\n",
    "memory.insert(k, v)\n",
    "q = torch.tensor([[1,1,1], [0,0,0]]).to(torch.float)\n",
    "k, v = memory(q)\n",
    "print(\"Memory:\",memory.k_memory)\n",
    "print(\"K,V\", k,v)\n",
    "\n",
    "# Insert again (notice that it's FIFO)\n",
    "k, v = torch.tensor([[5,5,5], [6,6,6], [7,7,7], [8,8,8]]).to(torch.float), torch.tensor([[5,5],[6,6],[7,7],[8,8]]).to(torch.float)\n",
    "memory.insert(k, v)\n",
    "q = torch.tensor([[1,1,1],[8,8,8]]).to(torch.float)\n",
    "k, v = memory(q)\n",
    "print(\"Memory:\",memory.k_memory)\n",
    "print(\"K,V\", k,v)\n",
    "\n",
    "# Check state dict stores memory \n",
    "file = './memory.pt'\n",
    "torch.save(memory.state_dict(), file)\n",
    "memory = KVMemory(k_features=3, v_features=2, memory_size=6, items_per_query=4)\n",
    "memory.load_state_dict(torch.load(file))\n",
    "# Query should return same result \n",
    "q = torch.tensor([[1,1,1],[8,8,8]]).to(torch.float)\n",
    "k, v = memory(q)\n",
    "print(\"Memory:\",memory.k_memory)\n",
    "print(\"K,V\", k,v)\n",
    "os.remove(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af74951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03985595703125\n",
      "torch.Size([4800, 256]) torch.Size([4800, 128])\n"
     ]
    }
   ],
   "source": [
    "memory = KVMemory(k_features=256, v_features=128, memory_size=100_000, items_per_query=16)\n",
    "\n",
    "start = time.time() \n",
    "k, v = memory(torch.rand(300, 256))\n",
    "print(time.time() - start)\n",
    "print(k.shape, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca9fd1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 256])\n",
      "Params: 852224\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import MABlock\n",
    "  \n",
    "block = MABlock(\n",
    "    in_features = 512,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16\n",
    ")\n",
    "\n",
    "out = block(torch.rand(32, 10, 512))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0238ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 256])\n",
      "Params: 854528\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import MemoformerBlock\n",
    "\n",
    "block = MemoformerBlock(\n",
    "    features = 256,\n",
    "    num_heads = 2,\n",
    "    dropout_attention = 0.1,\n",
    "    dropout_mlp = 0.1,\n",
    "    mlp_multiplier = 4,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16\n",
    ")\n",
    "out = block(torch.rand(2, 10, 256))\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(block)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "723e7b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 256])\n",
      "torch.Size([2, 1024, 256])\n",
      "Params: 3616512\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import ConvMemoTention\n",
    "\n",
    "encode = ConvMemoTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 2,\n",
    "    kernel_size = 4,\n",
    "    stride = 4,\n",
    "    padding = 0,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16,\n",
    "    dropout = 0.1\n",
    ")\n",
    "decode = ConvMemoTention(\n",
    "    in_features = 256,\n",
    "    out_features = 256,\n",
    "    num_heads = 8,\n",
    "    num_layers = 4,\n",
    "    out_patch_tokens = 4,\n",
    "    kernel_size = 2,\n",
    "    stride = 2,\n",
    "    padding = 0,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 16,\n",
    "    dropout = 0.1\n",
    ")\n",
    "\n",
    "out = encode(torch.rand(2, 1024, 256))\n",
    "print(out.shape)\n",
    "out = decode(out)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(encode)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0d31e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2048, 800])\n",
      "Params: 51052832\n"
     ]
    }
   ],
   "source": [
    "from brainle.models.architectures.attention import ConvMeNet\n",
    "\n",
    "net = ConvMeNet(\n",
    "    vocabulary_size = 800,\n",
    "    embedding_dim = 256,\n",
    "    num_layers = 7,\n",
    "    num_heads = 8,\n",
    "    num_attention_layers = 4,\n",
    "    window_size = 4,\n",
    "    use_skip = True,\n",
    "    memory_size = 50_000,\n",
    "    memory_items_per_query = 8,\n",
    ")\n",
    "\n",
    "x = torch.randint(low=0, high=800, size=(2, 2048))\n",
    "out = net(x)\n",
    "print(out.shape)\n",
    "print(f\"Params: {count_parameters(net)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbde72a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.]])\n",
      "K,V tensor([[4., 4., 4.],\n",
      "        [3., 3., 3.],\n",
      "        [2., 2., 2.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [0., 0., 0.]]) tensor([[4., 4.],\n",
      "        [3., 3.],\n",
      "        [2., 2.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [2., 2.],\n",
      "        [0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/x32rfnbd78n2jj1z9x_tgx9h0000gn/T/ipykernel_35150/2281732137.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices).to(q)\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import faiss.contrib.torch_utils\n",
    "\n",
    "class KVMemory(nn.Module):\n",
    "\n",
    "    \"\"\"Key value memory with FIFO replacement strategy.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, k_features: int, v_features: int, memory_size: int, items_per_query: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.k_features = k_features\n",
    "        self.v_features = v_features\n",
    "        self.memory_size = memory_size\n",
    "        self.items_per_query = items_per_query\n",
    "        # Initialize index for KNN search and memory\n",
    "        if torch.cuda.is_available():\n",
    "            index_cpu = faiss.IndexFlatIP(k_features)\n",
    "            self.index = faiss.index_cpu_to_all_gpus(index_cpu)\n",
    "        else:\n",
    "            self.index = faiss.IndexFlatIP(k_features)\n",
    "        self.index.add(np.zeros((memory_size, k_features), dtype=\"float32\"))\n",
    "        self.register_buffer(\"k_memory\", torch.zeros(memory_size, k_features))\n",
    "        self.register_buffer(\"v_memory\", torch.zeros(memory_size, v_features))\n",
    "\n",
    "    def insert(self, k: Tensor, v: Tensor):\n",
    "        (m, kd), (mv, vd) = k.shape, v.shape\n",
    "        assert m == mv, \"Expected same number of keys and values\"\n",
    "        assert m <= self.memory_size, \"More items inserted than memory size\"\n",
    "        assert kd == self.k_features, \"Expected k of shape [m, k_features]\"\n",
    "        assert vd == self.v_features, \"Expected v of shape [m, v_features]\"\n",
    "        # Update memory (with FIFO strategy)\n",
    "        self.k_memory = torch.cat([self.k_memory[m:], k.detach()])\n",
    "        self.v_memory = torch.cat([self.v_memory[m:], v.detach()])\n",
    "        # Update index\n",
    "        self.index.remove_ids(np.arange(m))\n",
    "        self.index.add(k)\n",
    "\n",
    "    def forward(self, q: Tensor):\n",
    "        \"\"\"Parses memory with query and returns keys, values.\"\"\"\n",
    "        # Dimensionality check\n",
    "        n, d = q.shape\n",
    "        assert d == self.k_features, f\"Expected tensor of shape [n, k_features]\"\n",
    "        # KNN search into index with `items_per_query` neighbors\n",
    "        i = self.items_per_query\n",
    "        distances, indices, embedding = self.index.search_and_reconstruct(q, i)\n",
    "        # Move to torch and same device\n",
    "        # distances = torch.tensor(distances).to(q)\n",
    "        # embedding = torch.tensor(embedding).to(q)\n",
    "        indices = torch.tensor(indices).to(q)\n",
    "        # Extract keys and values from memory\n",
    "        indices = rearrange(indices.to(torch.long), \"n i -> (n i)\")\n",
    "        k = self.k_memory[indices]\n",
    "        v = self.v_memory[indices]\n",
    "        # assert torch.all(k.eq(rearrange(embedding, 'n i d -> (n i) d'))), 'Index/memory mismatch.'\n",
    "        return k, v\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        k_memory_numpy = self.k_memory.cpu().numpy()\n",
    "        # Update to index\n",
    "        self.index.remove_ids(np.arange(self.memory_size))\n",
    "        self.index.add(k_memory_numpy)\n",
    "        \n",
    "        \n",
    "        \n",
    "# Build memory \n",
    "memory = KVMemory(k_features=3, v_features=2, memory_size=6, items_per_query=4)\n",
    "\n",
    "# Inseart and search\n",
    "k, v = torch.tensor([ [1,1,1], [2,2,2], [3,3,3], [4,4,4]]).to(torch.float), torch.tensor([[1,1],[2,2],[3,3], [4,4]]).to(torch.float)\n",
    "memory.insert(k, v)\n",
    "q = torch.tensor([[1,1,1], [0,0,0]]).to(torch.float)\n",
    "k, v = memory(q)\n",
    "print(\"Memory:\",memory.k_memory)\n",
    "print(\"K,V\", k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca3783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
