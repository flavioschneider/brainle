{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60316e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from typing import List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor, einsum\n",
    "from einops import parse_shape, rearrange, repeat\n",
    "from PIL import Image\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81c9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ede15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "def get_image_tensor(sidelength):\n",
    "    img = Image.open('stock.jpeg')        \n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "        torchvision.transforms.Resize(sidelength),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "class ImageFitting(torch.utils.data.Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        img = get_image_tensor(sidelength)\n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        if idx > 0: raise IndexError\n",
    "            \n",
    "        return self.coords, self.pixels\n",
    "    \n",
    "    \n",
    "cameraman = ImageFitting(256)\n",
    "dataloader = torch.utils.data.DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "img_siren = Siren(in_features=2, out_features=1, hidden_features=64, \n",
    "                  hidden_layers=1, outermost_linear=True)\n",
    "\n",
    "\n",
    "total_steps = 1000 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
    "steps_til_summary = 10\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-2, params=img_siren.parameters())\n",
    "\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "\n",
    "for step in range(total_steps):\n",
    "    model_output, coords = img_siren(model_input)    \n",
    "    loss = ((model_output - ground_truth)**2).mean()\n",
    "    \n",
    "    if not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
    "\n",
    "        fig, axes = plt.subplots(1,1, figsize=(6,6))\n",
    "        axes.imshow(model_output.cpu().view(256,256).detach().numpy(), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c21fef2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b1807eb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,1, figsize=(6,6))\n",
    "axes.imshow(img_siren.net[1].linear.weight.detach().numpy(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ec71b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    \"\"\"Sine Activation Function.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return torch.sin(30. * x)\n",
    "\n",
    "def first_layer_film_sine_init(m):\n",
    "    with torch.no_grad():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            num_input = m.weight.size(-1)\n",
    "            m.weight.uniform_(-1 / num_input, 1 / num_input)\n",
    "\n",
    "def kaiming_leaky_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.kaiming_normal_(m.weight, a=0.2, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "class CustomMappingNetwork(nn.Module):\n",
    "    def __init__(self, z_dim, map_hidden_dim, map_output_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(nn.Linear(z_dim, map_hidden_dim),\n",
    "                                     nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "                                    nn.Linear(map_hidden_dim, map_hidden_dim),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "                                    nn.Linear(map_hidden_dim, map_hidden_dim),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "                                    nn.Linear(map_hidden_dim, map_output_dim))\n",
    "\n",
    "        self.network.apply(kaiming_leaky_init)\n",
    "        with torch.no_grad():\n",
    "            self.network[-1].weight *= 0.25\n",
    "\n",
    "    def forward(self, z):\n",
    "        frequencies_offsets = self.network(z)\n",
    "        print(frequencies_offsets.shape)\n",
    "        frequencies = frequencies_offsets[..., :frequencies_offsets.shape[-1]//2]\n",
    "        phase_shifts = frequencies_offsets[..., frequencies_offsets.shape[-1]//2:]\n",
    "\n",
    "        return frequencies, phase_shifts\n",
    "\n",
    "\n",
    "def frequency_init(freq):\n",
    "    def init(m):\n",
    "        with torch.no_grad():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                num_input = m.weight.size(-1)\n",
    "                m.weight.uniform_(-np.sqrt(6 / num_input) / freq, np.sqrt(6 / num_input) / freq)\n",
    "    return init\n",
    "\n",
    "class FiLMLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, freq, phase_shift):\n",
    "        x = self.layer(x)\n",
    "        freq = freq.unsqueeze(1).expand_as(x)\n",
    "        phase_shift = phase_shift.unsqueeze(1).expand_as(x)\n",
    "        return torch.sin(freq * x + phase_shift)\n",
    "\n",
    "\n",
    "class TALLSIREN(nn.Module):\n",
    "    \"\"\"Primary SIREN  architecture used in pi-GAN generators.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=2, z_dim=100, hidden_dim=256, output_dim=1, device=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.input_dim = input_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.network = nn.ModuleList([\n",
    "            FiLMLayer(input_dim, hidden_dim),\n",
    "            FiLMLayer(hidden_dim, hidden_dim),\n",
    "            FiLMLayer(hidden_dim, hidden_dim),\n",
    "            FiLMLayer(hidden_dim, hidden_dim),\n",
    "            FiLMLayer(hidden_dim, hidden_dim),\n",
    "            FiLMLayer(hidden_dim, hidden_dim),\n",
    "            FiLMLayer(hidden_dim, hidden_dim),\n",
    "            FiLMLayer(hidden_dim, hidden_dim),\n",
    "        ])\n",
    "        self.final_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.color_layer_sine = FiLMLayer(hidden_dim + 3, hidden_dim)\n",
    "        self.color_layer_linear = nn.Sequential(nn.Linear(hidden_dim, 3), nn.Sigmoid())\n",
    "\n",
    "        self.mapping_network = CustomMappingNetwork(z_dim, 256, (len(self.network) + 1)*hidden_dim*2)\n",
    "\n",
    "        self.network.apply(frequency_init(25))\n",
    "        self.final_layer.apply(frequency_init(25))\n",
    "        self.color_layer_sine.apply(frequency_init(25))\n",
    "        self.color_layer_linear.apply(frequency_init(25))\n",
    "        self.network[0].apply(first_layer_film_sine_init)\n",
    "\n",
    "    def forward(self, input, z, ray_directions, **kwargs):\n",
    "        frequencies, phase_shifts = self.mapping_network(z)\n",
    "        return self.forward_with_frequencies_phase_shifts(input, frequencies, phase_shifts, ray_directions, **kwargs)\n",
    "\n",
    "    def forward_with_frequencies_phase_shifts(self, input, frequencies, phase_shifts, ray_directions, **kwargs):\n",
    "        frequencies = frequencies*15 + 30\n",
    "\n",
    "        x = input\n",
    "\n",
    "        for index, layer in enumerate(self.network):\n",
    "            start = index * self.hidden_dim\n",
    "            end = (index+1) * self.hidden_dim\n",
    "            x = layer(x, frequencies[..., start:end], phase_shifts[..., start:end])\n",
    "\n",
    "        sigma = self.final_layer(x)\n",
    "        rbg = self.color_layer_sine(torch.cat([ray_directions, x], dim=-1), frequencies[..., -self.hidden_dim:], phase_shifts[..., -self.hidden_dim:])\n",
    "        rbg = self.color_layer_linear(rbg)\n",
    "\n",
    "        return torch.cat([rbg, sigma], dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb03f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 8704])\n",
      "torch.Size([26, 4352]) torch.Size([26, 4352])\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "length = 16\n",
    "\n",
    "z = torch.randn((26, hidden_dim))\n",
    "z\n",
    "\n",
    "mapping_network = CustomMappingNetwork(hidden_dim, hidden_dim, (length + 1)*hidden_dim*2)\n",
    "out = mapping_network(z)\n",
    "print(out[0].shape, out[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0decb87e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64, 20, 3]) torch.Size([10, 64, 20, 1]) torch.Size([10, 64, 3])\n",
      "tensor([[0.8800],\n",
      "        [0.8926],\n",
      "        [0.9053],\n",
      "        [0.9179],\n",
      "        [0.9305],\n",
      "        [0.9432],\n",
      "        [0.9558],\n",
      "        [0.9684],\n",
      "        [0.9811],\n",
      "        [0.9937],\n",
      "        [1.0063],\n",
      "        [1.0189],\n",
      "        [1.0316],\n",
      "        [1.0442],\n",
      "        [1.0568],\n",
      "        [1.0695],\n",
      "        [1.0821],\n",
      "        [1.0947],\n",
      "        [1.1074],\n",
      "        [1.1200]])\n",
      "torch.Size([10, 64, 20, 3]) torch.Size([10, 64, 20, 1]) torch.Size([10, 64, 3]) torch.Size([10, 64, 3]) torch.Size([10, 1]) torch.Size([10, 1])\n",
      "tensor([-0.1040,  0.1040, -0.9891])\n",
      "tensor([-0.2465, -0.0646, -0.9670])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def normalize_vecs(vectors: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalize vector lengths.\n",
    "    \"\"\"\n",
    "    return vectors / (torch.norm(vectors, dim=-1, keepdim=True))\n",
    "\n",
    "\n",
    "def get_initial_rays_trig(n, num_steps, device, fov, resolution, ray_start, ray_end):\n",
    "    \"\"\"Returns sample points, z_vals, and ray directions in camera space.\"\"\"\n",
    "\n",
    "    W, H = resolution\n",
    "    # Create full screen NDC (-1 to +1) coords [x, y, 0, 1].\n",
    "    # Y is flipped to follow image memory layouts.\n",
    "    x, y = torch.meshgrid(torch.linspace(-1, 1, W, device=device),\n",
    "                          torch.linspace(1, -1, H, device=device))\n",
    "    x = x.T.flatten()\n",
    "    y = y.T.flatten()\n",
    "    z = -torch.ones_like(x, device=device) / np.tan((2 * math.pi * fov / 360)/2)\n",
    "\n",
    "    rays_d_cam = normalize_vecs(torch.stack([x, y, z], -1))\n",
    "\n",
    "\n",
    "    z_vals = torch.linspace(ray_start, ray_end, num_steps, device=device).reshape(1, num_steps, 1).repeat(W*H, 1, 1)\n",
    "    points = rays_d_cam.unsqueeze(1).repeat(1, num_steps, 1) * z_vals\n",
    "\n",
    "    points = torch.stack(n*[points])\n",
    "    z_vals = torch.stack(n*[z_vals])\n",
    "    rays_d_cam = torch.stack(n*[rays_d_cam]).to(device)\n",
    "\n",
    "    return points, z_vals, rays_d_cam\n",
    "\n",
    "\n",
    "points_cam, z_vals, rays_d_cam = get_initial_rays_trig(n=10, num_steps=20, device='cpu', fov=12, resolution=(8, 8), ray_start=0.88, ray_end=1.12)\n",
    "\n",
    "# Note: all points are in camera space:\n",
    "# Points: all points of all rays: (b, h*w, steps, coord)\n",
    "# Z-vals: all distances form start pixel for all rays: (b, h*w, steps, dist) interpolated from ray_start->ray_end\n",
    "# Rays-d cam: all d starting points for each pixel (b, h*w, dir)\n",
    "\n",
    "print(points.shape, z_vals.shape, rays_d_cam.shape)\n",
    "#print(rays_d_cam[0])\n",
    "print(z_vals[0][0])\n",
    "\n",
    "\n",
    "def perturb_points(points, z_vals, ray_directions, device):\n",
    "    distance_between_points = z_vals[:,:,1:2,:] - z_vals[:,:,0:1,:]\n",
    "    offset = (torch.rand(z_vals.shape, device=device)-0.5) * distance_between_points\n",
    "    z_vals = z_vals + offset\n",
    "\n",
    "    points = points + offset * ray_directions.unsqueeze(2)\n",
    "    return points, z_vals\n",
    "\n",
    "def sample_camera_positions(device, n=1, r=1, horizontal_stddev=1, vertical_stddev=1, horizontal_mean=math.pi*0.5, vertical_mean=math.pi*0.5, mode='normal'):\n",
    "    \"\"\"\n",
    "    Samples n random locations along a sphere of radius r. Uses the specified distribution.\n",
    "    Theta is yaw in radians (-pi, pi)\n",
    "    Phi is pitch in radians (0, pi)\n",
    "    \"\"\"\n",
    "\n",
    "    if mode == 'uniform':\n",
    "        theta = (torch.rand((n, 1), device=device) - 0.5) * 2 * horizontal_stddev + horizontal_mean\n",
    "        phi = (torch.rand((n, 1), device=device) - 0.5) * 2 * vertical_stddev + vertical_mean\n",
    "\n",
    "    elif mode == 'normal' or mode == 'gaussian':\n",
    "        theta = torch.randn((n, 1), device=device) * horizontal_stddev + horizontal_mean\n",
    "        phi = torch.randn((n, 1), device=device) * vertical_stddev + vertical_mean\n",
    "\n",
    "    elif mode == 'hybrid':\n",
    "        if random.random() < 0.5:\n",
    "            theta = (torch.rand((n, 1), device=device) - 0.5) * 2 * horizontal_stddev * 2 + horizontal_mean\n",
    "            phi = (torch.rand((n, 1), device=device) - 0.5) * 2 * vertical_stddev * 2 + vertical_mean\n",
    "        else:\n",
    "            theta = torch.randn((n, 1), device=device) * horizontal_stddev + horizontal_mean\n",
    "            phi = torch.randn((n, 1), device=device) * vertical_stddev + vertical_mean\n",
    "\n",
    "    elif mode == 'truncated_gaussian':\n",
    "        theta = truncated_normal_(torch.zeros((n, 1), device=device)) * horizontal_stddev + horizontal_mean\n",
    "        phi = truncated_normal_(torch.zeros((n, 1), device=device)) * vertical_stddev + vertical_mean\n",
    "\n",
    "    elif mode == 'spherical_uniform':\n",
    "        theta = (torch.rand((n, 1), device=device) - .5) * 2 * horizontal_stddev + horizontal_mean\n",
    "        v_stddev, v_mean = vertical_stddev / math.pi, vertical_mean / math.pi\n",
    "        v = ((torch.rand((n,1), device=device) - .5) * 2 * v_stddev + v_mean)\n",
    "        v = torch.clamp(v, 1e-5, 1 - 1e-5)\n",
    "        phi = torch.arccos(1 - 2 * v)\n",
    "\n",
    "    else:\n",
    "        # Just use the mean.\n",
    "        theta = torch.ones((n, 1), device=device, dtype=torch.float) * horizontal_mean\n",
    "        phi = torch.ones((n, 1), device=device, dtype=torch.float) * vertical_mean\n",
    "\n",
    "    phi = torch.clamp(phi, 1e-5, math.pi - 1e-5)\n",
    "\n",
    "    output_points = torch.zeros((n, 3), device=device)\n",
    "    output_points[:, 0:1] = r*torch.sin(phi) * torch.cos(theta)\n",
    "    output_points[:, 2:3] = r*torch.sin(phi) * torch.sin(theta)\n",
    "    output_points[:, 1:2] = r*torch.cos(phi)\n",
    "\n",
    "    return output_points, phi, theta\n",
    "\n",
    "def create_cam2world_matrix(forward_vector, origin, device=None):\n",
    "    \"\"\"Takes in the direction the camera is pointing and the camera origin and returns a cam2world matrix.\"\"\"\n",
    "\n",
    "    forward_vector = normalize_vecs(forward_vector)\n",
    "    up_vector = torch.tensor([0, 1, 0], dtype=torch.float, device=device).expand_as(forward_vector)\n",
    "\n",
    "    left_vector = normalize_vecs(torch.cross(up_vector, forward_vector, dim=-1))\n",
    "\n",
    "    up_vector = normalize_vecs(torch.cross(forward_vector, left_vector, dim=-1))\n",
    "\n",
    "    rotation_matrix = torch.eye(4, device=device).unsqueeze(0).repeat(forward_vector.shape[0], 1, 1)\n",
    "    rotation_matrix[:, :3, :3] = torch.stack((-left_vector, up_vector, -forward_vector), axis=-1)\n",
    "\n",
    "    translation_matrix = torch.eye(4, device=device).unsqueeze(0).repeat(forward_vector.shape[0], 1, 1)\n",
    "    translation_matrix[:, :3, 3] = origin\n",
    "\n",
    "    cam2world = translation_matrix @ rotation_matrix\n",
    "\n",
    "    return cam2world\n",
    "\n",
    "def transform_sampled_points(points, z_vals, ray_directions, device, h_stddev=1, v_stddev=1, h_mean=math.pi * 0.5, v_mean=math.pi * 0.5, mode='normal'):\n",
    "    \"\"\"Samples a camera position and maps points in camera space to world space.\"\"\"\n",
    "\n",
    "    n, num_rays, num_steps, channels = points.shape\n",
    "\n",
    "    points, z_vals = perturb_points(points, z_vals, ray_directions, device)\n",
    "\n",
    "\n",
    "    camera_origin, pitch, yaw = sample_camera_positions(n=points.shape[0], r=1, horizontal_stddev=h_stddev, vertical_stddev=v_stddev, horizontal_mean=h_mean, vertical_mean=v_mean, device=device, mode=mode)\n",
    "    forward_vector = normalize_vecs(-camera_origin)\n",
    "\n",
    "    cam2world_matrix = create_cam2world_matrix(forward_vector, camera_origin, device=device)\n",
    "\n",
    "    points_homogeneous = torch.ones((points.shape[0], points.shape[1], points.shape[2], points.shape[3] + 1), device=device)\n",
    "    points_homogeneous[:, :, :, :3] = points\n",
    "\n",
    "    # should be n x 4 x 4 , n x r^2 x num_steps x 4\n",
    "    transformed_points = torch.bmm(cam2world_matrix, points_homogeneous.reshape(n, -1, 4).permute(0,2,1)).permute(0, 2, 1).reshape(n, num_rays, num_steps, 4)\n",
    "\n",
    "\n",
    "    transformed_ray_directions = torch.bmm(cam2world_matrix[..., :3, :3], ray_directions.reshape(n, -1, 3).permute(0,2,1)).permute(0, 2, 1).reshape(n, num_rays, 3)\n",
    "\n",
    "    homogeneous_origins = torch.zeros((n, 4, num_rays), device=device)\n",
    "    homogeneous_origins[:, 3, :] = 1\n",
    "    transformed_ray_origins = torch.bmm(cam2world_matrix, homogeneous_origins).permute(0, 2, 1).reshape(n, num_rays, 4)[..., :3]\n",
    "\n",
    "    return transformed_points[..., :3], z_vals, transformed_ray_directions, transformed_ray_origins, pitch, yaw\n",
    "\n",
    "\n",
    "transformed_points, z_vals, transformed_ray_directions, transformed_ray_origins, pitch, yaw = transform_sampled_points(points_cam, z_vals, rays_d_cam, h_stddev=0.3, v_stddev=0.155, h_mean=math.pi*0.5, v_mean=math.pi*0.5, device='cpu', mode='gaussian')\n",
    "\n",
    "print(transformed_points.shape, z_vals.shape, transformed_ray_directions.shape, transformed_ray_origins.shape, pitch.shape, yaw.shape)\n",
    "\n",
    "print(rays_d_cam[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImplicitGenerator3d(nn.Module):\n",
    "    def __init__(self, siren, z_dim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.siren = TALLSIREN(output_dim=4, z_dim=self.z_dim, input_dim=3, device=None)\n",
    "        self.epoch = 0\n",
    "        self.step = 0\n",
    "\n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "        self.siren.device = device\n",
    "\n",
    "        self.generate_avg_frequencies()\n",
    "\n",
    "    def forward(self, z, img_size, fov, ray_start, ray_end, num_steps, h_stddev, v_stddev, h_mean, v_mean, hierarchical_sample, sample_dist=None, lock_view_dependence=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Generates images from a noise vector, rendering parameters, and camera distribution.\n",
    "        Uses the hierarchical sampling scheme described in NeRF.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = z.shape[0]\n",
    "\n",
    "        # Generate initial camera rays and sample points.\n",
    "        with torch.no_grad():\n",
    "            points_cam, z_vals, rays_d_cam = get_initial_rays_trig(batch_size, num_steps, resolution=(img_size, img_size), device=self.device, fov=fov, ray_start=ray_start, ray_end=ray_end) # batch_size, pixels, num_steps, 1\n",
    "            transformed_points, z_vals, transformed_ray_directions, transformed_ray_origins, pitch, yaw = transform_sampled_points(points_cam, z_vals, rays_d_cam, h_stddev=h_stddev, v_stddev=v_stddev, h_mean=h_mean, v_mean=v_mean, device=self.device, mode=sample_dist)\n",
    "\n",
    "            transformed_ray_directions_expanded = torch.unsqueeze(transformed_ray_directions, -2)\n",
    "            transformed_ray_directions_expanded = transformed_ray_directions_expanded.expand(-1, -1, num_steps, -1)\n",
    "            transformed_ray_directions_expanded = transformed_ray_directions_expanded.reshape(batch_size, img_size*img_size*num_steps, 3)\n",
    "            transformed_points = transformed_points.reshape(batch_size, img_size*img_size*num_steps, 3)\n",
    "\n",
    "            if lock_view_dependence:\n",
    "                transformed_ray_directions_expanded = torch.zeros_like(transformed_ray_directions_expanded)\n",
    "                transformed_ray_directions_expanded[..., -1] = -1\n",
    " \n",
    "        # Model prediction on course points\n",
    "        coarse_output = self.siren(transformed_points, z, ray_directions=transformed_ray_directions_expanded).reshape(batch_size, img_size * img_size, num_steps, 4)\n",
    "\n",
    "        # Re-sample fine points along camera rays, as described in NeRF\n",
    "        if hierarchical_sample:\n",
    "            with torch.no_grad():\n",
    "                transformed_points = transformed_points.reshape(batch_size, img_size * img_size, num_steps, 3)\n",
    "                _, _, weights = fancy_integration(coarse_output, z_vals, device=self.device, clamp_mode=kwargs['clamp_mode'], noise_std=kwargs['nerf_noise'])\n",
    "\n",
    "                weights = weights.reshape(batch_size * img_size * img_size, num_steps) + 1e-5\n",
    "\n",
    "                #### Start new importance sampling\n",
    "                z_vals = z_vals.reshape(batch_size * img_size * img_size, num_steps)\n",
    "                z_vals_mid = 0.5 * (z_vals[: ,:-1] + z_vals[: ,1:])\n",
    "                z_vals = z_vals.reshape(batch_size, img_size * img_size, num_steps, 1)\n",
    "                fine_z_vals = sample_pdf(z_vals_mid, weights[:, 1:-1],\n",
    "                                 num_steps, det=False).detach()\n",
    "                fine_z_vals = fine_z_vals.reshape(batch_size, img_size * img_size, num_steps, 1)\n",
    "\n",
    "\n",
    "                fine_points = transformed_ray_origins.unsqueeze(2).contiguous() + transformed_ray_directions.unsqueeze(2).contiguous() * fine_z_vals.expand(-1,-1,-1,3).contiguous()\n",
    "                fine_points = fine_points.reshape(batch_size, img_size*img_size*num_steps, 3)\n",
    "\n",
    "                if lock_view_dependence:\n",
    "                    transformed_ray_directions_expanded = torch.zeros_like(transformed_ray_directions_expanded)\n",
    "                    transformed_ray_directions_expanded[..., -1] = -1\n",
    "                #### end new importance sampling\n",
    "\n",
    "            # Model prediction on re-sampled find points\n",
    "            fine_output = self.siren(fine_points, z, ray_directions=transformed_ray_directions_expanded).reshape(batch_size, img_size * img_size, -1, 4)\n",
    "\n",
    "            # Combine course and fine points\n",
    "            all_outputs = torch.cat([fine_output, coarse_output], dim = -2)\n",
    "            all_z_vals = torch.cat([fine_z_vals, z_vals], dim = -2)\n",
    "            _, indices = torch.sort(all_z_vals, dim=-2)\n",
    "            all_z_vals = torch.gather(all_z_vals, -2, indices)\n",
    "            all_outputs = torch.gather(all_outputs, -2, indices.expand(-1, -1, -1, 4))\n",
    "        else:\n",
    "            all_outputs = coarse_output\n",
    "            all_z_vals = z_vals\n",
    "\n",
    "\n",
    "        # Create images with NeRF\n",
    "        pixels, depth, weights = fancy_integration(all_outputs, all_z_vals, device=self.device, white_back=kwargs.get('white_back', False), last_back=kwargs.get('last_back', False), clamp_mode=kwargs['clamp_mode'], noise_std=kwargs['nerf_noise'])\n",
    "\n",
    "        pixels = pixels.reshape((batch_size, img_size, img_size, 3))\n",
    "        pixels = pixels.permute(0, 3, 1, 2).contiguous() * 2 - 1\n",
    "\n",
    "        return pixels, torch.cat([pitch, yaw], -1)\n",
    "    \n",
    "    \n",
    "    def generate_avg_frequencies(self):\n",
    "        \"\"\"Calculates average frequencies and phase shifts\"\"\"\n",
    "\n",
    "        z = torch.randn((10000, self.z_dim), device=self.siren.device)\n",
    "        with torch.no_grad():\n",
    "            frequencies, phase_shifts = self.siren.mapping_network(z)\n",
    "        self.avg_frequencies = frequencies.mean(0, keepdim=True)\n",
    "        self.avg_phase_shifts = phase_shifts.mean(0, keepdim=True)\n",
    "        return self.avg_frequencies, self.avg_phase_shifts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa76d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
