{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b789d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "184742b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import Tensor, einsum\n",
    "from einops import parse_shape, rearrange, repeat\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_parameters_all(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d7ce5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/Users/flavioschneider/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet size 837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What does t ts tirn met ? Ieteetettee  einttin  o   a  ei  e eeeine  e aeotiia  in  a eeie eeititttios .........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text 005\n",
    "\n",
    "from brainle.models.sm_model import SMModel\n",
    "from brainle.models.architectures.attention import ConvTeNet\n",
    "from brainle.datamodules.wikitext_datamodule import WikiTextDatamodule\n",
    "\n",
    "block_size = 1024\n",
    "\n",
    "datamodule = WikiTextDatamodule(\n",
    "    train_val_split =  [10537, 100],\n",
    "    batch_size = 24, \n",
    "    num_workers = 0,\n",
    "    block_size = block_size,\n",
    "    p_word_mask = 0.15,\n",
    "    p_char_mask = 0.05\n",
    ")\n",
    "datamodule.setup()\n",
    "\n",
    "net = ConvTeNet(\n",
    "    vocabulary_size = 837,\n",
    "    embedding_dim = 256,\n",
    "    num_layers = 7,\n",
    "    num_heads = 8,\n",
    "    num_attention_layers = 4,\n",
    "    window_size = 4,\n",
    "    use_skip = True\n",
    ")\n",
    "model = SMModel.load_from_checkpoint(\n",
    "    checkpoint_path = '../data/ckpts/text_008_last.ckpt', \n",
    "    model = net,\n",
    "    learning_rate = 1e-4\n",
    ")\n",
    "\n",
    "text = 'WXat doXs XXXs XXXn meXX? XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX '\n",
    "input_tokens = rearrange(torch.tensor(datamodule.dataset.encode(text.ljust(block_size, '.'))), 'n -> 1 n')\n",
    "input_mask = rearrange(torch.tensor([1] * block_size), 'n -> 1 n')\n",
    "\n",
    "for i in range(len(text)):\n",
    "    if text[i] == 'X':\n",
    "        input_mask[:,i] = 0\n",
    "\n",
    "out = F.softmax(model(input_tokens, input_mask), dim=-1)\n",
    "ids = torch.topk(out, k=1, dim=-1)[1]\n",
    "ids = rearrange(ids, \"1 s 1 -> s\").numpy()\n",
    "out_text = datamodule.dataset.decode(ids)\n",
    "out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101f6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
